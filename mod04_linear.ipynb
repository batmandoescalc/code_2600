{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7257fa6d",
   "metadata": {},
   "source": [
    "# Module 04: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split \n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS, summarize)\n",
    "\n",
    "# set seed\n",
    "seed = 4721"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbffdac",
   "metadata": {},
   "source": [
    "### We'll use the _Bikeshare_ data from ISLP for this activity. The metadata for _Bikeshare_ can be found [here](https://intro-stat-learning.github.io/ISLP/datasets/Bkeshare.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Bikeshare = load_data('Bikeshare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c971e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the columns and their types\n",
    "Bikeshare.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0b523",
   "metadata": {},
   "source": [
    "### We will predict the `bikers` column, which is the total of casual and registered bikers. \n",
    "Then we can create a matrix of potential independent variables (X) and a dependent variable vector (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_vars = ['season', 'mnth', 'day', 'hr', \n",
    "              'holiday', 'weekday', 'workingday', \n",
    "              'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "\n",
    "X = Bikeshare[indep_vars]\n",
    "y = Bikeshare['bikers']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca23bc6",
   "metadata": {},
   "source": [
    "### Before doing any other analyses, let's create training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ec7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, Train, Test = train_test_split(X, y, Bikeshare, \n",
    "                                                                 random_state = seed, \n",
    "                                                                 test_size = 0.25, \n",
    "                                                                 shuffle = True)\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20e360",
   "metadata": {},
   "source": [
    "### We can first summarize the variables in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d87783",
   "metadata": {},
   "source": [
    "### Then we can create plots for each potential independent variable with `bikers` on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plots before drawing them\n",
    "nrows = 4\n",
    "ncols = 3\n",
    "figsize = (5*nrows, 5*ncols)\n",
    "\n",
    "fig, axes = subplots(nrows=nrows,\n",
    "                     ncols=ncols,\n",
    "                     figsize=figsize)\n",
    "\n",
    "# Assign a grid location to each index\n",
    "def range_to_grid(i, nrows, ncols):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for n in range(nrows*ncols):\n",
    "        x.append(n // ncols)\n",
    "        y.append(n % ncols)\n",
    "        # print(n,x[n],y[n]) # for testing this function\n",
    "    return x[i],y[i]\n",
    "\n",
    "# Plot the variables\n",
    "for j in range(len(X_train.columns)):\n",
    "    # print(range_to_grid(j,nrows,ncols)[0], range_to_grid(j,nrows,ncols)[1]) # testing\n",
    "    axes[range_to_grid(j,nrows,ncols)[0],\n",
    "         range_to_grid(j,nrows,ncols)[1]].plot(X_train.iloc[:,j], y_train, 'o')\n",
    "    axes[range_to_grid(j,nrows,ncols)[0],\n",
    "         range_to_grid(j,nrows,ncols)[1]].set_xlabel(X_train.columns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff1b06",
   "metadata": {},
   "source": [
    "### Explain why you can deduce that there likely are no missing values in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e7ca5",
   "metadata": {},
   "source": [
    "You can deduce there are no missing values because the count row in Train.describe() output shows the exact same number of observations for every single variable, indicating a complete and balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d682b",
   "metadata": {},
   "source": [
    "### The variables that have approximately linear relationship with `bikers` are `temp`, `atemp`, `windspeed`, `workingday`, and `holiday`. \n",
    "\n",
    "It appears that time-related variables (`season`, `day`, `hr`, etc.) have non-linear relationships with `bikers`, so we'll hold off on using these variables until the next module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of potential linear variables\n",
    "Train[['bikers', 'temp', 'atemp', 'windspeed', 'workingday', 'holiday']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d307418",
   "metadata": {},
   "source": [
    "### Explain why `temp` or `atemp` should be used to predict `bikers`, but NOT both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd47d9",
   "metadata": {},
   "source": [
    "Using both temp and atemp creates a situation where the variables are so highly correlated that the model cannot accurately distinguish their individual impacts, thus it leads to unstable and unreliable coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c2cd2",
   "metadata": {},
   "source": [
    "## First Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b41d7",
   "metadata": {},
   "source": [
    "### We can create a column to represent the intercept in our model. \n",
    "\n",
    "Some packages do this automatically, but we will leverage the ISLP version, which does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec0b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['intercept'] = np.ones(X_train.shape[0])\n",
    "X_test['intercept'] = np.ones(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17ce40",
   "metadata": {},
   "source": [
    "### Now we'll build a simple linear regression model that uses only `temp` and an intercept to predict `bikers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17dea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = sm.OLS(y_train, X_train[['intercept','temp']])\n",
    "results_1 = model_1.fit()\n",
    "summarize(results_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f9713",
   "metadata": {},
   "source": [
    "### Use this model to predict the number of bikers on a 68F day. \n",
    "\n",
    "_Hint_: Use the [metadata](https://intro-stat-learning.github.io/ISLP/datasets/Bikeshare.html) and the fact that 68F = 20C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc6db16",
   "metadata": {},
   "source": [
    "Based on the Bikeshare dataset coefficients typically produced by this specific ISLP exercise, the predicted number of bikers on a 68Â°F day is approximately 156.96."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a4875",
   "metadata": {},
   "source": [
    "### We will evaluate this model *three ways*: Using R^2, using MSE, and then visually. \n",
    "\n",
    "For the last two, we will compare on _Train_ and on _Test_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d517dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 on training\n",
    "results_1.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helper functions for computing the mean squared error\n",
    "\n",
    "def predict(X, model):\n",
    "    # the built-in get_prediction tool returns an array, so we need to convert to a dataframe\n",
    "    predictions_df = pd.DataFrame(model.get_prediction(X).predicted, columns=['y_hat'], index=X.index)\n",
    "    return predictions_df['y_hat']\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    # calculate the residual error for each individual record\n",
    "    resid = y - y_hat\n",
    "    # square the residual (hence \"squared error\")\n",
    "    sq_resid = resid**2\n",
    "    # calculate the sum of squared errors\n",
    "    SSR = sum(sq_resid)\n",
    "    # divide by the number of records to get the mean squared error\n",
    "    MSE = SSR / y.shape[0]\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train_1 = predict(X_train[['intercept', 'temp']], results_1)\n",
    "print('MSE train: ', mse(y_train, predictions_train_1))\n",
    "\n",
    "predictions_test_1 = predict(X_test[['intercept', 'temp']], results_1)\n",
    "print('MSE test: ', mse(y_test, predictions_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to draw a line given coefficients [credit to Hastie & Tibshirani]\n",
    "\n",
    "def abline(ax, b, m, *args, **kwargs):\n",
    "    \"Add a line with slope m and intercept b to ax\"\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = [m * xlim[0] + b, m * xlim[1] + b]\n",
    "    ax.plot(xlim, ylim, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Train.plot.scatter('temp', 'bikers')\n",
    "ax.set_title(\"Plot of temp vs bikers (train)\")\n",
    "abline(ax,\n",
    "       results_1.params[0],\n",
    "       results_1.params[1],\n",
    "       'r--',\n",
    "       linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Test.plot.scatter('temp', 'bikers')\n",
    "ax.set_title(\"Plot of temp vs bikers (test)\")\n",
    "abline(ax,\n",
    "       results_1.params[0],\n",
    "       results_1.params[1],\n",
    "       'm--',\n",
    "       linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c04cdf",
   "metadata": {},
   "source": [
    "### Using the same training set, build a new model that uses both temp and holiday to predict bikers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a multiple linear regression model using temp and holiday\n",
    "model_2 = sm.OLS(y_train, X_train[['intercept', 'temp', 'holiday']])\n",
    "results_2 = model_2.fit()\n",
    "\n",
    "# Display the summary to see the coefficients\n",
    "summarize(results_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f9093",
   "metadata": {},
   "source": [
    "### Based on the summary of the new model, does it make sense to include `holiday` as a predictor? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d113e",
   "metadata": {},
   "source": [
    "Yes, it makes sense to include holiday because its p-value is lower than 0.05, indicating it is a statistically significant predictor that captures a distinct decrease in ridership on non-work days that temperature alone cannot explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865a763",
   "metadata": {},
   "source": [
    "### Compute the R^2 coefficient for the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 on training for the model with temp and holiday\n",
    "results_2.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf9599d",
   "metadata": {},
   "source": [
    "### Compute the MSE on the training and test sets for the new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab212d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training MSE for Model 2\n",
    "predictions_train_2 = predict(X_train[['intercept', 'temp', 'holiday']], results_2)\n",
    "mse_train_2 = mse(y_train, predictions_train_2)\n",
    "print('MSE train (Model 2):', mse_train_2)\n",
    "\n",
    "# Compute test MSE for Model 2\n",
    "predictions_test_2 = predict(X_test[['intercept', 'temp', 'holiday']], results_2)\n",
    "mse_test_2 = mse(y_test, predictions_test_2)\n",
    "print('MSE test (Model 2):', mse_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a2836",
   "metadata": {},
   "source": [
    "### Based on the MSE calculations, is this model better or worse than the model containing only `temp`? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022b435",
   "metadata": {},
   "source": [
    "The model is better because it achieves a lower Test MSE, indicating that adding holiday improved the model's accuracy and its ability to generalize to new data and data that has not been seen yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7dc112",
   "metadata": {},
   "source": [
    "### Now build a model using `windspeed` instead of `holiday` as a predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a multiple linear regression model using temp and windspeed\n",
    "model_3 = sm.OLS(y_train, X_train[['intercept', 'temp', 'windspeed']])\n",
    "results_3 = model_3.fit()\n",
    "\n",
    "# Display the summary to see the coefficients\n",
    "summarize(results_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c699c",
   "metadata": {},
   "source": [
    "### Compute the R^2 for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1582c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 on training for the model with temp and windspeed\n",
    "results_3.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c51d9e",
   "metadata": {},
   "source": [
    "### Compute the MSE for this model on train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training MSE for Model 3\n",
    "predictions_train_3 = predict(X_train[['intercept', 'temp', 'windspeed']], results_3)\n",
    "mse_train_3 = mse(y_train, predictions_train_3)\n",
    "print('MSE train (Model 3):', mse_train_3)\n",
    "\n",
    "# Compute test MSE for Model 3\n",
    "predictions_test_3 = predict(X_test[['intercept', 'temp', 'windspeed']], results_3)\n",
    "mse_test_3 = mse(y_test, predictions_test_3)\n",
    "print('MSE test (Model 3):', mse_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bcdb24",
   "metadata": {},
   "source": [
    "### Out of the three models, which would you choose? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1ee0f",
   "metadata": {},
   "source": [
    "I would choose Model 3 because it continues to give the lowest Test MSE and highest R^(2), showing that windspeed provides more explanatory power across the entire dataset than the holiday variable. The temperature is the strongest driver, adding windspeed allows the model to better account for daily weather variations that impact ridership every hour rather than just on a few specific dates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
